{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1. Import the required libraries.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2.Define the train and test dataset loader.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the directories to read the data\n",
    "train_directory = 'root/train'\n",
    "test_directory = 'root/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadTrainTest(train_dir, test_dir, batch_size):\n",
    "    # Transformation for image transforms.Grayscale(1), \n",
    "    transformation = transforms.Compose([ transforms.Grayscale(1),\n",
    "                                             transforms.Resize((28,28)),\n",
    "                                                 transforms.ToTensor(), \n",
    "                                                        transforms.Normalize((0.5, ), (0.5, ))])\n",
    "   # transformation1 = transforms.Compose([transforms.Resize(28),\n",
    "                                          #transforms.Grayscale(), transforms.ToTensor(), \n",
    "                                     #transforms.Normalize((0.5, ), (0.5, ))])\n",
    "    \n",
    "    # Load train and test dataset with ImageFolder\n",
    "    train_dataset = datasets.ImageFolder(root = train_dir, \n",
    "                                         transform = transformation)\n",
    "    test_dataset = datasets.ImageFolder(root = test_dir, \n",
    "                                        transform = transformation)\n",
    "    \n",
    "    # Load train and test dataset into batches\n",
    "    trainloader = torch.utils.data.DataLoader(dataset = train_dataset, \n",
    "                                         batch_size = batch_size,\n",
    "                                         shuffle = True)\n",
    "    testloader = torch.utils.data.DataLoader(dataset = test_dataset, \n",
    "                                         batch_size = batch_size,\n",
    "                                         shuffle = True)\n",
    "    return trainloader, testloader, train_dataset.classes\n",
    "\n",
    "\n",
    "batch_size = int(input('Enter batch size. '))\n",
    "train_load, test_load, classes = loadTrainTest(train_directory, test_directory, batch_size)\n",
    "\n",
    "print('Classes: ', classes) # print number of classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3.Show a batch of images__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(image):\n",
    "    if isinstance(image, torch.Tensor):\n",
    "        image = image.numpy().transpose((1, 2, 0))  # (C, H, W) ---> (H, W, C)\n",
    "    else:\n",
    "        image = np.array(image).transpose((1, 2, 0))\n",
    "    # unnormalize\n",
    "    image = 0.5*image + 0.5\n",
    "    # Plot\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(image)\n",
    "    \n",
    "    \n",
    "# get some random training images\n",
    "images, labels = next(iter(train_load))\n",
    "imshow(torchvision.utils.make_grid(images))  # show images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__4. Define the architecture of your network.__<br>___Use the following information:___\n",
    "* ```Conv1```: A convolutional layer that takes the non colored image as input and passes it through ```6``` filters of size ```5```.\n",
    "* ```Pool1```: Use a pooling layer after each convolutional layer, with a filter size of ```2```.\n",
    "* ```Conv2```: A convolutional layer that passes the input data through ```16``` filters of size ```5```.\n",
    "* ```Pool2```: Use a pooling layer after each convolutional layer, with a filter size of ```2```.\n",
    "* ```Linear1```: A fully connected layer that receives the flattened matrix from the previous layer as input and generates an output of ```120``` units.\n",
    "* ```Linear2```: A fully connected layer that generates ```84``` of outputs.\n",
    "* ```Linear3```: A fully connected layer that generates ```10``` outputs, one for each class label. \n",
    "* Use the ```ReLU``` activation function after each convolutional layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeezNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GeezNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(16*4*4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        # print('shape of X: 'x.shape) input.view(batch_size, -1\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = GeezNet()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>__4. Define a Loss function and optimizer__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lossAndoptimizer(ls, op, lr = 1e-2):\n",
    "    loss_func = {'entropy' : nn.CrossEntropyLoss(), \n",
    "                         'nll': nn.NLLLoss() }\n",
    "    \n",
    "    optimizer_func = {'sgd': optim.SGD(model.parameters(), lr), \n",
    "                          'adam': optim.Adam(model.parameters(), lr),\n",
    "                             'adagrad': optim.Adagrad(model.parameters(), lr),\n",
    "                                 'rms': optim.RMSprop(model.parameters(), lr) }\n",
    "    \n",
    "    return loss_func[ls], optimizer_func[op]\n",
    "\n",
    "\n",
    "loss_f = input(''' Write the type of loss function you want. \n",
    "                        'entropy' for CrossEntropyLoss \n",
    "                        'nll' for NLLLoss \\n''')\n",
    "\n",
    "print()\n",
    "optimizer_f = input('''Write the type of optimizer function you want.\n",
    "                        'sgd' for SGD \n",
    "                        'adam' for Adam\n",
    "                        'rms' for RMSprop\n",
    "                        'adagrad' for Adagrad \\n''')\n",
    "\n",
    "print(f'\\nSelected loss function: {loss_f} \\nSelected optimizer function: {optimizer_f}')\n",
    "criterion, optimizer = lossAndoptimizer(loss_f, optimizer_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__5. Train your model.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(trainload, criteria, optimizer, epochs):\n",
    "    print('\\nTraining started.......\\n')\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0       # Set the running loss at each epoch to zero\n",
    "        for i, data in enumerate(trainload):\n",
    "            inputs, labels = data  # get the inputs; data is a list of [inputs, labels]\n",
    "            optimizer.zero_grad()  # clear the gradient\n",
    "            outputs = model(inputs) # feed the input and acquire the output from network\n",
    "            loss = criterion(outputs, labels) # calculating the predicted and the expected loss\n",
    "            loss.backward()    # Backpropagation\n",
    "            optimizer.step()    # update the parameters\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 20000 == 0: # print every 96 mini-batches\n",
    "                print(f\"ephoch {epoch + 1}, loss {loss.item():.4f}\")\n",
    "                print('-----------------------')\n",
    "    print('\\nFinished Training!')\n",
    "    return model\n",
    "    \n",
    "epochs = int(input('Enter the number of epochs. '))    \n",
    "model = train_model(train_load, criterion, optimizer, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__6.Testing the model.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "get some random testing images\n",
    "make an iterator from test_loader\n",
    "Get a batch of training images\n",
    "\"\"\"\n",
    "images, labels = next(iter(test_load))\n",
    "\n",
    "# print images and labels\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model(images)\n",
    "_, predicted = torch.max(results, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range(batch_size)))\n",
    "\n",
    "fig2 = plt.figure()\n",
    "plt.subplots_adjust(top = 0.99)\n",
    "for i in range(batch_size):\n",
    "    fig2.add_subplot(2,2, i+1)\n",
    "    plt.title('truth ' + classes[labels[i]] + ': predict ' + classes[predicted[i]])\n",
    "    img = images[i] / 2 + 0.5     # this is to unnormalize the image\n",
    "    img = torchvision.transforms.ToPILImage()(img)\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network performance\n",
    "def accuracy(model, test_load):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_load:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total, correct, total\n",
    "\n",
    "acc, correct, total  = accuracy(model, test_load)\n",
    "print(f'Accuracy of the network on the {total} test images is: {acc}')\n",
    "print(f'{correct} images out of {total} are correctly predicted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison b/n different loss and optimizer\n",
    "| epoch |Loss  | Optimizer | Accuracy |\n",
    "|:------|:-----------:|:----------:|:------|\n",
    "|20|CrossEntropyLoss|SGD|55.23809523809524|\n",
    "|20|CrossEntropyLoss|Adam|39.04761904761905|\n",
    "|20|CrossEntropyLoss|RMSprop|38.095238095238095|\n",
    "|20|CrossEntropyLoss|Adagrad|54.76190476190476|\n",
    "|20|NLLLoss|SGD|63.333333333333336|\n",
    "|20|NLLLoss|Adam|35.23809523809524|\n",
    "|20|NLLLoss|RMSprop|45.23809523809524|\n",
    "|20|NLLLoss|Adagrad|57.61904761904762|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
